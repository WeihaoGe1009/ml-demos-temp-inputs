{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM23oxQmWHb5et5zRitVHDg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["You can just click **Runtime ‚Üí Run all** to try the demo."],"metadata":{"id":"aDp2mvKDEZ2A"}},{"cell_type":"markdown","source":["# Module 2 - Simple Neural Network: Identify Handwritten digits\n","\n","In this notebook, we examin how a multilayer perceptron (MLP) identifies hand-written digits.\n","\n","An MLP is a simple neural network with:\n","- An **input layer** that receives the raw data\n","- One or more **hidden layers** that learn patterns (edges, curves, etc.)\n","- An **output layer** that gives a prediction (here: digit 0‚Äì9)\n","\n","We use:\n","\n","* Modified National Institute of Standards and Technology (MNIST) data set, which includes handwritten digits labeled as 0-9\n","\n","MLP demonstrates that machines could learn patterns from data, not by following rules, but by adjusting internal connections based on examples. This idea laid the foundation for most modern AI systems.\n"],"metadata":{"id":"lNuzifAhC2ku"}},{"cell_type":"code","source":["%%capture\n","#@title System set-up, install and load packages {display-mode: \"form\"}\n","\n","!pip ipywidgets\n","\n","import numpy as np                     # for numerical operations\n","import matplotlib.pyplot as plt        # for plotting digits and visualizations\n","import seaborn as sns\n","import tensorflow as tf                # for building and training the neural network\n","\n","from tensorflow.keras import layers    # for concise model building\n","import requests # for url request\n","\n","# Optional: for interactive visualizations (if used later)\n","import ipywidgets as widgets\n","from IPython.display import display\n","\n","# suppress warnings\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"JJL34z0NEzTf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load and Visualize MNIST\n","The digit dataset we're using here ‚Äî **MNIST** ‚Äî was created in the 1990s from scanned handwriting samples collected in controlled settings. Each image is paired with a known label (0‚Äì9) and was designed for machine learning research. It is now built in the Python TensorFlow package and can be loaded directly.\n","\n","\n","### Where Does Labeled Data Come From?\n","\n","Different from MNIST, in many modern systems, labeled data comes from **users in the wild**.\n","\n","You‚Äôve likely encountered challenges like this while browsing the web:\n","\n","> \"Select all images with traffic lights\"  \n","> \"Click every square that contains a bus\"\n","\n","These tasks come from **reCAPTCHA**, a system designed to verify that users are human.  \n","But they also serve another purpose: helping improve machine learning models by collecting **labeled data**.\n","\n","This raises important legal and ethical questions:\n","- Are users aware they are contributing to machine learning datasets?\n","- Do they consent to how their input is used?\n","- What are the implications for data ownership?\n","\n","As we train a simple digit classifier in this notebook, it's worth reflecting on how the **source and intent of labeled data** might affect how we interpret the role of machine learning in society."],"metadata":{"id":"U7TTsSgDF7tg"}},{"cell_type":"code","source":["#@title Load MNIST from TensorFlow's built-in datasets {display-mode: \"form\"}\n","from tensorflow.keras.datasets import mnist\n","\n","# Load training and test data\n","# x: images (28x28 pixels), y: labels (0‚Äì9 digits)\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","print(f\"Training samples: {x_train.shape[0]}\")\n","print(f\"Test samples: {x_test.shape[0]}\")"],"metadata":{"id":"fmWoXe6NFRRw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Now we can take a look at the first 10 images in the training data set from MNIST {display-mode: \"form\"}\n","# Plot the first 10 images from the training set\n","fig, axes = plt.subplots(1, 10, figsize=(12, 2))\n","\n","for i in range(10):\n","    axes[i].imshow(x_train[i], cmap='gray')\n","    axes[i].set_title(f\"Label: {y_train[i]}\")\n","    axes[i].axis('off')\n","\n","plt.suptitle(\"Examples of Handwritten Digits (MNIST)\", fontsize=14)\n","plt.tight_layout()\n","plt.show()\n","\n","\n","# then there are still some small toggles to make the images compatible for model training\n","# Normalize pixel values to range [0, 1] for neural network input\n","x_train = x_train.astype(\"float32\") / 255.0\n","x_test = x_test.astype(\"float32\") / 255.0\n","\n","#print(\"Pixel values normalized to [0, 1]\")\n","\n","# flatten the image\n","# Each image is 28x28 ‚Üí flatten to 784-dimensional vector for MLP\n","x_train_flat = x_train.reshape(-1, 28 * 28)\n","x_test_flat = x_test.reshape(-1, 28 * 28)\n","\n","#print(f\"Shape of flattened input: {x_train_flat.shape[1]} features per image, ready to feed into the model.\")"],"metadata":{"id":"vnoNUCirFqQi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Build/Load an MLP\n","\n","Now that we have the training data set ready, we can start explore the MLP. Here, we provide a pre-trained model on our github repository. We also provide a code below to train this pre-trained model just to save time.\n","\n"],"metadata":{"id":"L4PgOik3GmP6"}},{"cell_type":"code","source":["#@title code to construct and train a simple MLP {display-mode: \"form\"}\n","# build and define the model\n","\n","def build_and_train_model(x_train, y_train, epochs=5):\n","\n","  # Functional API: define model with named intermediate layers\n","  inputs = tf.keras.Input(shape=(784,), name=\"input_layer\")\n","  x = layers.Dense(64, activation='relu', name=\"hidden_layer\")(inputs)\n","  outputs = layers.Dense(10, activation='softmax', name=\"output_layer\")(x)\n","\n","  # Build the full model\n","  model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_mlp\")\n","  model.summary()\n","\n","  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","\n","  # Compile the model: define loss function, optimizer, and evaluation metric\n","  model.compile(\n","      optimizer='adam',\n","      loss='sparse_categorical_crossentropy',\n","      metrics=['accuracy']\n","      )\n","\n","  # Train the model on training data (this runs fast in Colab)\n","  history = model.fit(\n","      x_train_flat, y_train,\n","      validation_split=0.1,   # Use 10% of training set for validation\n","      epochs=epochs,\n","      batch_size=32,\n","      verbose=1\n","      )\n","\n","  # Save to disk for later download\n","  model.save(\"mlp_model.h5\")\n","  print(\"Model trained and saved as 'mlp_model.h5'.\")\n","\n","  return model"],"metadata":{"id":"yLjOG2uhQIha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Load the MLP, or train from scratch {display-mode: \"form\"}\n","\n","#model_url = \"https://github.com/WeihaoGe1009/ml-demos-temp-inputs/raw/main/mlp_model.h5\"\n","\n","url_header = \"https://github.com/WeihaoGe1009/ml-demos-temp-inputs/raw/main/\"\n","module_name = \"\"\n","model_dir = url_header+module_name+''\n","\n","#url_header = https://github.com/WeihaoGe1009/ai-history-for-ip-scholars/faw/main/\n","#module_name = \"02_neural_networks/\"\n","#model_dir = url_header + module_name + \"models/\"\n","\n","model_file = model_dir + 'mlp_model.h5'\n","\n","try:\n","\n","    print(\" Attempting to download model from GitHub...\")\n","\n","    response = requests.get(model_file, allow_redirects=True)\n","    response.raise_for_status()\n","\n","    if response.status_code == 200:\n","      print(\"Pretrained model found. Loading from GitHub...\")\n","\n","\n","      # Check if GitHub served us HTML instead of a binary file\n","      if \"text/html\" in response.headers.get(\"Content-Type\", \"\"):\n","        raise ValueError(\"Received HTML instead of binary model file.\")\n","\n","      # Save binary content\n","      local_path = '/tmp/mlp_model.h5'\n","      with open(local_path, \"wb\") as f:\n","        f.write(response.content)\n","\n","      # Load model using tf.keras\n","      model = tf.keras.models.load_model(local_path)\n","      print(\"Model successfully loaded from GitHub.\")\n","\n","    else:\n","        raise ValueError(\"Model not found or unavailable.\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Could not load model: {e}\")\n","    print(\"üîÅ Training a new model instead...\")\n","    model = build_and_train_model(x_train_flat, y_train)\n","\n","# Evaluate how well the model performs on unseen test data\n","test_loss, test_accuracy = model.evaluate(x_test_flat, y_test, verbose=0)\n","print(f\"\\nTest accuracy: {test_accuracy:.4f}\")"],"metadata":{"id":"ofR9oPR4RLZg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualizing how hidden layers respond to digit images\n","\n","What do we see in the hidden layer? We won't see digits. The hidden layer will learn to detect patterns, like edges, curves, or blobs"],"metadata":{"id":"KGzie8tGI3Rl"}},{"cell_type":"code","source":["#@title Plot the first 10 hidden neuron weight patterns as 28x28 images {display-mode: \"form\"}\n","# Get the weights from the hidden layer, which captures the underlying patterns\n","hidden_layer = model.get_layer(\"hidden_layer\") # weights shape: (784, 128)\n","weights, biases = hidden_layer.get_weights()  # weights shape: (784, 64)\n","\n","print(f\"Shape of weights matrix: {weights.shape}\")\n","\n","fig, axes = plt.subplots(2, 5, figsize=(6, 4))\n","\n","for i, ax in enumerate(axes.flat):\n","    # Extract weights for the i-th neuron and reshape\n","    neuron_weights = weights[:, i].reshape(28, 28)\n","    ax.imshow(neuron_weights, cmap='gray', interpolation='nearest')\n","    ax.set_title(f\"Neuron {i}\")\n","    ax.axis('off')\n","\n","plt.suptitle(\"Visualizing Weights of Hidden Neurons (First Layer)\", fontsize=14)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"XweR1Yi3I__F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## What Do These Neurons \"See\"?\n","\n","Each hidden neuron has learned to respond to certain **patterns** in the input images.  \n","These patterns are encoded in the neuron's weights ‚Äî shown here as 28√ó28 grayscale images.\n","\n","From these images, we can see that:\n","- Some neurons focus on strokes in specific **regions** of the digit\n","- Others respond to **curved or rounded shapes**\n","- These learned patterns can be **combined and reused** by the network to recognize full digits\n","\n","These are not full digits ‚Äî they are **building blocks**, like loops, arcs, or partial strokes.  \n","By layering and combining them, the network learns to tell apart digits like `3`, `6`, and `8`.\n","\n","> What the network learns reflects the **statistical patterns** in the training data ‚Äî  \n","> in this case, handwritten digits composed of many curved elements.\n"],"metadata":{"id":"9d2MSErbJFnh"}},{"cell_type":"code","source":["#@title View Hidden-layer Neuron Activation Pattern {display-mode: \"form\"}\n","\n","# Create a small model that gives access to the hidden layer's output\n","activation_model = tf.keras.Model(\n","    inputs=model.input,\n","    outputs=model.get_layer(\"hidden_layer\").output\n",")\n","\n","# Select a few test samples (e.g., digits 2, 3, 7, 8)\n","sample_indices = [np.where(y_test == d)[0][0] for d in [2, 3, 7, 8]]\n","sample_images = x_test_flat[sample_indices]\n","sample_labels = y_test[sample_indices]\n","\n","# Get activations from the second layer\n","activations = activation_model.predict(sample_images)\n","\n","activation_matrix = activations  # shape: (4 digits, 64 neurons)\n","\n","plt.figure(figsize=(10, 1.5))  # short height, wide width\n","sns.heatmap(\n","    activation_matrix,\n","    cmap='YlGn_r',\n","    cbar=False,                  # remove color bar\n","    yticklabels=sample_labels,   # show digits on the left\n","    xticklabels=False,           # hide neuron labels\n","    linewidths=0, linecolor='none'\n",")\n","\n","plt.title(\"Neurons Activated by Each Digit\", fontsize=12)\n","plt.xlabel(\"Hidden Neurons\")\n","plt.ylabel(\"Digit\")\n","plt.yticks(rotation=0)\n","plt.tick_params(axis='both', which='major', labelsize=10)\n","plt.xlabel(\"Hidden Neurons\", fontsize=10)\n","plt.ylabel(\"Digit\", fontsize=10)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"fbALSK5PM9fP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generating Digit-Like Images.\n","\n","This model learns how digits look ‚Äî not just to recognize them, but to redraw them from memory.\n","It studies many examples, compresses the patterns into a smaller form, and then reconstructs what it \"thinks\" the digit should look like.\n","\n","When we give it the number 5, it doesn‚Äôt copy a specific image of hand-written 5 ‚Äî it generates a new one using the features it has learned.\n","\n","If we give it the same number multiple times, it can draw slightly different versions ‚Äî just like people never write the exact same digit twice."],"metadata":{"id":"vxwYswRYPaLt"}},{"cell_type":"markdown","source":["### \"Prototype\" digit\n","For each digit, we calculate an average activation pattern. We assume the hand-writing to of the same digit correspond to a similar pattern. Therefore, the average activation pattern will show a \"prototype\" digit. The generated \"prototype\" does not belong to any pre-existing images in the data set, but created based on the recombination of the \"patterns\" learnt in each neuron"],"metadata":{"id":"8RKscZBn2qB3"}},{"cell_type":"code","source":["#@title Step 1 ‚Äî Precompute the Avecrage Activation for Each Digit {display-mode: \"form\"}\n","# Dictionary to hold mean and std activations for digits 0‚Äì9\n","activation_stats = {}\n","\n","for label in range(10):\n","    indices = np.where(y_train == label)[0]\n","    images = x_train_flat[indices]\n","    activations = activation_model.predict(images, verbose=0)\n","\n","    mean_act = np.mean(activations, axis=0)\n","\n","    activation_stats[label] = mean_act\n"],"metadata":{"id":"N2Qs1HM3NlgW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Step 2 - Define the Function that Combines the Patterns by Activation Stats {display-mode: \"form\"}\n","def visualize_activation_projection(label):\n","    \"\"\"\n","    Generate a synthetic activation pattern for a given digit label\n","    and project it back to pixel space using hidden layer weights.\n","    \"\"\"\n","    # Retrieve mean and std from precomputed stats\n","    synthetic_activation = activation_stats[label]\n","\n","    # Get hidden layer weights\n","    weights = hidden_layer.get_weights()[0]  # shape (784, 64)\n","\n","\n","    # Combine each neuron's weight map with its activation\n","    combined_image = np.zeros((28, 28))\n","    for i in range(64):\n","        neuron_weights_2d = weights[:, i].reshape(28, 28)\n","        combined_image += synthetic_activation[i] * neuron_weights_2d\n","\n","    # Normalize image for display\n","    combined_image -= combined_image.min()\n","    combined_image /= combined_image.max()\n","\n","\n","    return combined_image\n","\n","    # Plot\n","    #plt.figure(figsize=(2.5, 2.5))\n","    #plt.imshow(combined_image, cmap='gray')\n","    #plt.title(f\"Projection of Synthetic Activation for Digit {label}\")\n","    #plt.axis('off')\n","    #plt.tight_layout()\n","    #plt.show()\n"],"metadata":{"id":"kF6oQ3nJ4LV5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Step 3, Show the Prototype Digits {display-mode: \"form\"}\n","fig, axes = plt.subplots(2, 5, figsize=(6, 3))\n","for label in range(10):\n","  ax = axes[label//5, label % 5]\n","  image = visualize_activation_projection(label)\n","  ax.imshow(image, cmap='gray')\n","  ax.set_title(f\"Digit {label}\")\n","  ax.axis('off')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"XsWd1RWp7UFC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see the prototype digits are very blurry, but some numbers are discernible in the center. The neural network algorithm will create some artifacts at the edge, which resulted in the halo around the digits. These prototype digits are created by the model, instead of extracted from the data set."],"metadata":{"id":"IYyho1fE6wof"}},{"cell_type":"markdown","source":["### Take-Home Message: What We Learned\n","In this notebook, we explored how a simple neural network can learn to recognize hand-written digits.\n","\n","Along the way, we introduced:\n","\n","* Categorization ‚Äî how the network classifies images into labels (0‚Äì9)\n","\n","* Pattern Learning ‚Äî how it identifies shared strokes and shapes across digits\n","\n","* Neuron Activation ‚Äî how internal layers respond differently depending on what digit is shown\n","\n","* Prototype Digits ‚Äî how we can reconstruct what the network ‚Äúexpects‚Äù a digit to look like using only activation patterns\n","\n","We‚Äôve shown that the model isn‚Äôt memorizing specific examples. Instead, it‚Äôs learning generalizable visual patterns, which can even be used to generate new digit-like images without copying.\n","\n","In the next notebook, we‚Äôll go further:\n","\n","We‚Äôll explore convolutional neural networks (CNNs) and show how they can process images in a more advanced way ‚Äî identifying edges, corners, and more.\n","\n","We‚Äôll also revisit image generation ‚Äî this time starting from pure noise ‚Äî and demonstrate how a well-trained model can turn randomness into some scribbles."],"metadata":{"id":"B15siQcsaOmc"}}]}