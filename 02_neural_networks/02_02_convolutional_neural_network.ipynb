{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPKloZks/5L5m/TgkeTDV3K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["You can just click **Runtime ‚Üí Run all** to try the demo."],"metadata":{"id":"VX7BDkBrBYc8"}},{"cell_type":"markdown","source":["## Module 2 cont. - Seeing Like a Machine: Patterns, Vision, and Imagination\n","In the first notebook, we worked with a simple type of neural network ‚Äî enough to recognize hand-written digits and generate the \"average\" or \"prototype\" digits using learned patterns.\n","\n","In real-world applications ‚Äî including many where copyright concerns arise ‚Äî machines often rely on more complex neural structures to process images. One of the most widely used is the **convolutional neural network**, or CNN. This architecture is more powerful, and it's also more common in systems that create or transform visual content.\n","\n","In this notebook, we‚Äôll explore:\n","\n","* How these more advanced networks ‚Äúsee‚Äù patterns in images\n","\n","* How a trained model can go beyond recognition and start creating new digit-like images from what it has learned"],"metadata":{"id":"ZtCJVcx4cUbj"}},{"cell_type":"code","source":["#@title System setup {display-mode: \"form\"}\n","!pip install -q tensorflow matplotlib\n","\n","#Import required packages\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras import Model, Input\n","from tensorflow.keras.layers import Conv2DTranspose, Reshape\n","\n","import requests\n","\n","# supress warnings\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","import absl.logging\n","absl.logging.set_verbosity(absl.logging.ERROR)"],"metadata":{"id":"VXU16dEKcYDj","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We are using MNIST data again, and see how a slightly more complex neural network learns features in the handwritten digits."],"metadata":{"id":"8EJKJXOIn2oD"}},{"cell_type":"code","source":["#@title Load and prepare MNIST data {display-mode: \"form\"}\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","# Normalize and reshape\n","x_train = x_train.astype(\"float32\") / 255.\n","x_test = x_test.astype(\"float32\") / 255.\n","\n","x_train = np.expand_dims(x_train, -1)  # shape: (60000, 28, 28, 1)\n","x_test = np.expand_dims(x_test, -1)\n"],"metadata":{"id":"LUlH8TiJczO7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### CNN Classifier\n","Now that we have training and testing data set ready, we are ready to look at a simplest CNN classifier that, like the simple neural network / MLP we saw in the last notebook, \"recognizes\" what digits are in the handwritting."],"metadata":{"id":"7HXB7vTWLe-L"}},{"cell_type":"code","source":["#@title code to construct and train a CNN Classifier {display-mode: \"form\"}\n","def build_and_train_cnn_classifier(x_train, y_train, epochs=5):\n","\n","  input_img = tf.keras.Input(shape=(28, 28, 1), name=\"input\")\n","  x = layers.Conv2D(32, (3, 3), activation='relu', name=\"conv1\")(input_img)\n","  x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n","  x = layers.Conv2D(64, (3, 3), activation='relu', name=\"conv2\")(x)\n","  x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n","  x = layers.Flatten(name=\"flatten\")(x)\n","  x = layers.Dense(64, activation='relu', name=\"dense1\")(x)\n","  output = layers.Dense(10, activation='softmax', name=\"output\")(x)\n","\n","  cnn_classifier = tf.keras.Model(inputs=input_img, outputs=output)\n","  cnn_classifier.compile(optimizer='adam',\n","                       loss='sparse_categorical_crossentropy',\n","                       metrics=['accuracy'])\n","  #Train CNN Classifier on MNIST {display-mode: \"form\"}\n","  cnn_classifier.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.1)\n","\n","  # Save to disk for later download\n","  cnn_classifier.save(\"cnn_classifier.h5\")\n","  print(\"Model trained and saved as 'cnn_classifier.h5'.\")\n","\n","\n","  return cnn_classifier"],"metadata":{"id":"bl9SJkX6oCv4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Load the cnn_classifier, or train from scratch {display-mode: \"form\"}\n","\n","#model_url = \"https://github.com/WeihaoGe1009/ml-demos-temp-inputs/raw/main/mlp_model.h5\"\n","\n","url_header = \"https://github.com/WeihaoGe1009/ml-demos-temp-inputs/raw/main/\"\n","module_name = \"\"\n","model_dir = url_header+module_name+''\n","\n","#url_header = https://github.com/WeihaoGe1009/ai-history-for-ip-scholars/raw/main/\n","#module_name = \"02_neural_networks/\"\n","#model_dir = url_header + module_name + \"models/\"\n","\n","model_file = model_dir + 'cnn_model.h5'\n","\n","try:\n","\n","    print(\" Attempting to download model from GitHub...\")\n","\n","    response = requests.get(model_file, allow_redirects=True)\n","    response.raise_for_status()\n","\n","    if response.status_code == 200:\n","      print(\"Pretrained model found. Loading from GitHub...\")\n","\n","\n","      # Check if GitHub served us HTML instead of a binary file\n","      if \"text/html\" in response.headers.get(\"Content-Type\", \"\"):\n","        raise ValueError(\"Received HTML instead of binary model file.\")\n","\n","      # Save binary content\n","      local_path = '/tmp/cnn_generator.h5'\n","      with open(local_path, \"wb\") as f:\n","        f.write(response.content)\n","\n","      # Load model using tf.keras\n","      cnn_classifier = tf.keras.models.load_model(local_path)\n","      print(\"Model successfully loaded from GitHub.\")\n","\n","    else:\n","        raise ValueError(\"Model not found or unavailable.\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Could not load model: {e}\")\n","    print(\"üîÅ Training a new model instead...\")\n","    cnn_classifier = build_and_train_cnn_classifier(x_train, y_train)\n","\n","# Evaluate how well the model performs on unseen test data\n","test_loss, test_accuracy = cnn_classifier.evaluate(x_test, y_test, verbose=0)\n","print(f\"\\nTest accuracy: {test_accuracy:.4f}\")"],"metadata":{"id":"obBQjeUJp6EU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Visualize filters from first Conv2D layer {display-mode: \"form\"}\n","first_conv = cnn_classifier.get_layer(\"conv1\")\n","filters, biases = first_conv.get_weights()  # filters shape: (3, 3, 1, 32)\n","\n","# Normalize for display\n","f_min, f_max = filters.min(), filters.max()\n","filters = (filters - f_min) / (f_max - f_min)\n","\n","fig, axes = plt.subplots(4, 8, figsize=(10, 5))\n","for i, ax in enumerate(axes.flat):\n","    ax.imshow(filters[:, :, 0, i], cmap='gray')\n","    ax.axis('off')\n","fig.suptitle(\"First-layer filters learned by CNN\")\n","plt.show()\n"],"metadata":{"id":"uJamN-f_dTRA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The tiny 3√ó3 filters shown above don‚Äôt look like digits ‚Äî and they‚Äôre not supposed to.\n","Instead, each filter acts like a small lens that picks up local visual signals, such as slight changes in brightness, orientation, or texture.\n","These filters are the first layer of processing in a convolutional neural network (CNN), a more advanced type of neural network used widely in real-world image recognition systems.\n","While each filter detects only a very basic aspect, the model builds on these pieces ‚Äî layer by layer ‚Äî to recognize or even generate complete images like digits.\n","This modular structure is a key idea in understanding how machines learn visual patterns without memorizing images."],"metadata":{"id":"zJni-eYsoscJ"}},{"cell_type":"markdown","source":["\n","### From Pure Noise to a Scribble Image\n","In this section, the model starts with **pure noise** ‚Äî a random 28√ó28 image ‚Äî and tries to \"imagine\" a digit using only the patterns it learned during training.\n","\n","This shift ‚Äî from recognizing patterns to generating new images ‚Äî raises thoughtful questions about how machines learn, and what it means for a result to be ‚Äúnew‚Äù or ‚Äúinspired‚Äù in the context of intellectual work.\n","\n","This is not a memory recall or a copy-paste. It's a **synthesis**: the model combines patterns like loops, strokes, and shapes that it believes are typical of hand-written digits.\n","\n","This simplified process is related to the way **modern Generative AI** works:\n","- Start from noise\n","- Refine it using learned structure\n","- Generate something *plausible*, but not retrieved from storage\n","\n","Each run generates a different result ‚Äî a different \"interpretation\" of what a digit might look like.\n"],"metadata":{"id":"IXXXno2XrCFD"}},{"cell_type":"code","source":["#@title code to construct and train a CNN generator based on CNN Classifier\n","def build_and_train_cnn_generator(x_train, y_train, cnn_classifier, epochs=5):\n","\n","  # Freeze encoder layers to retain pretrained weights from cnn_classifier\n","  for layer in cnn_classifier.layers:\n","    if layer.name != \"output\":  # skip output layer, since we're reusing everything up to dense1\n","        layer.trainable = False\n","\n","  # Reuse encoder layers from the trained cnn_classifier\n","  encoder_input = cnn_classifier.input\n","  encoder_output = cnn_classifier.get_layer(\"dense1\").output  # shape: (None, 64)\n","\n","  # Decoder: mirror of encoder layers in reverse\n","  x = layers.Dense(7 * 7 * 64, activation='relu', name=\"dense_decode\")(encoder_output)\n","  x = Reshape((7, 7, 64), name=\"reshape_decode\")(x)\n","  x = Conv2DTranspose(64, (3, 3), activation='relu', strides=2, padding='same', name=\"deconv1\")(x)\n","  x = Conv2DTranspose(32, (3, 3), activation='relu', strides=2, padding='same', name=\"deconv2\")(x)\n","  decoded_output = Conv2DTranspose(1, (3, 3), activation='tanh', padding='same', name=\"decoder_output\")(x)\n","\n","  cnn_generator = Model(inputs=encoder_input, outputs=decoded_output, name=\"cnn_generator\")\n","  cnn_generator.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","  # Train using the original images as both input and output (autoencoder-style training)\n","  cnn_generator.fit(x_train, x_train, epochs=epochs, batch_size=128, validation_split=0.1)\n","\n","\n","  # Save to disk for later download\n","  cnn_generator.save(\"cnn_generator.h5\")\n","  print(\"Model trained and saved as 'cnn_generator.h5'.\")\n","\n","  return cnn_generator"],"metadata":{"cellView":"form","id":"fW7wuhCKNRpx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Load the cnn_generator, or train from scratch {display-mode: \"form\"}\n","\n","#model_url = \"https://github.com/WeihaoGe1009/ml-demos-temp-inputs/raw/main/mlp_model.h5\"\n","\n","url_header = \"https://github.com/WeihaoGe1009/ml-demos-temp-inputs/raw/main/\"\n","module_name = \"\"\n","model_dir = url_header+module_name+''\n","\n","#url_header = https://github.com/WeihaoGe1009/ai-history-for-ip-scholars/raw/main/\n","#module_name = \"02_neural_networks/\"\n","#model_dir = url_header + module_name + \"models/\"\n","\n","model_file = model_dir + 'cnn_generator.h5'\n","\n","try:\n","\n","    print(\" Attempting to download model from GitHub...\")\n","\n","    response = requests.get(model_file, allow_redirects=True)\n","    response.raise_for_status()\n","\n","    if response.status_code == 200:\n","      print(\"Pretrained model found. Loading from GitHub...\")\n","\n","\n","      # Check if GitHub served us HTML instead of a binary file\n","      if \"text/html\" in response.headers.get(\"Content-Type\", \"\"):\n","        raise ValueError(\"Received HTML instead of binary model file.\")\n","\n","      # Save binary content\n","      local_path = '/tmp/cnn_generator.h5'\n","      with open(local_path, \"wb\") as f:\n","        f.write(response.content)\n","\n","      # Load model using tf.keras\n","      cnn_generator = tf.keras.models.load_model(local_path)\n","      print(\"Model successfully loaded from GitHub.\")\n","\n","    else:\n","        raise ValueError(\"Model not found or unavailable.\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Could not load model: {e}\")\n","    print(\"üîÅ Training a new model instead...\")\n","    #cnn_generator = build_and_train_cnn_generator(x_train, x_train, cnn_classifier)\n","\n","# Evaluate how well the model performs on unseen test data\n","#cnn_generator.compile(optimizer='adam', loss='binary_crossentropy')\n","#test_loss = cnn_generator.evaluate(x_test, x_test)"],"metadata":{"id":"R-7HkecyOwgo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title generate image from random noise {display-mode: \"form\"}\n","num_samples = 4\n","random_images = np.random.normal(loc=0.0, scale=1.0, size=(num_samples, 28, 28, 1))\n","\n","# Feed the noise images through the full CNN generator model\n","generated_images = cnn_generator.predict(random_images)\n","\n","# Plot input noise and output digit side-by-side\n","fig, axes = plt.subplots(2, num_samples, figsize=(num_samples * 1.5, 3))\n","for i in range(num_samples):\n","    # Top row: input noise\n","    axes[0, i].imshow(random_images[i].squeeze(), cmap='gray')\n","    axes[0, i].axis('off')\n","    axes[0, i].set_title(\"Noise\", fontsize=8)\n","\n","    # Bottom row: generated digit-like image\n","    axes[1, i].imshow(generated_images[i].squeeze(), cmap='gray')\n","    axes[1, i].axis('off')\n","    axes[1, i].set_title(\"Generated\", fontsize=8)\n","\n","fig.suptitle(\"CNN Generator: Creating Digits from Noise\", fontsize=12)\n","plt.tight_layout()\n"],"metadata":{"id":"N-iogXfyRTk2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The images generated above looks like hand-written scribbles. They are mostly resembling 8, 3, 6, or 2. In this simplest architecture of CNN, it is easier to capture or \"learn\" curves, and generate images based on the patterns the model has learnt."],"metadata":{"id":"_AQAgbBQYtQy"}},{"cell_type":"markdown","source":["### Take-home message: What we've learned\n","\n","In this notebook, we explored how a convolutional neural network (CNN) can learn to recognize hand-written digits, and generate some digit-like scribbles from pure random.\n","\n","We have found:\n","\n","* The model learns filters that detect small visual features common in many digits.\n","\n","* These filters shape how the model interprets or constructs digit-like forms.\n","\n","* The scribble outputs come from applying learned filters to random input.\n"],"metadata":{"id":"fYULlhg8VUG2"}},{"cell_type":"code","source":[],"metadata":{"id":"bqaM83uoYsdD"},"execution_count":null,"outputs":[]}]}